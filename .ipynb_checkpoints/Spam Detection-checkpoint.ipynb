{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the spamassassin public corpus we can attempt to classify spam emails by observing the frequency at which words appear in spam and non-spam (ham) e-mails. The framework used to do this is supervised classifier known as Naive Bayes; which estimates the posterior distribution of each document based on these frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get spam and ham data from the spamassassin public corpus. These will be extracted separately into the spam folder in datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", HAM_URL), (\"spam.tar.bz2\", SPAM_URL)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide different directory addresses which will be passed onto the reader function. Two lists are created to iterate through all the filenames after extracting the tarball file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Given a file name we can open it using the open method. There are some invalid characters that we need to strip out which can be done using a sequence of regular expressions. Any string of characters delimited by a space that has a non-alphabetical letter is removed from the e-mail. The read_email function returns a Counter object of what words occur in the e-mail and to what frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "regex_rules = {\n",
    "    'tags' : '<[^>]*>',\n",
    "    'brackets': '\\([^\\)]*\\)',\n",
    "    'newline': '(\\n+)'\n",
    "}\n",
    "\n",
    "# Get the words of an email given a filename\n",
    "def read_email(fname, spam = 0):\n",
    "    url = os.path.join(SPAM_DIR if spam else HAM_DIR, fname)\n",
    "    \n",
    "    with open(url, \"rb\") as f:\n",
    "        try:\n",
    "            chunk = str(f.read())\n",
    "            for k, v in regex_rules.items():\n",
    "                chunk = re.sub(v, '', chunk)\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "        \n",
    "    chunk_to_words = chunk.split(' ')\n",
    "    words = set([word.lower() for word in chunk_to_words if re.match('^[a-zA-Z]+$', word) and len(word) > 2])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run this function on the spam and ham files and label them appropriately into spam (1) and ham (0). First iterate through all the counter objects to see what words occur most frequently across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ham_words = [(read_email(file_name), 0) for file_name in ham_filenames]\n",
    "spam_words = [(read_email(file_name,1), 1) for file_name in spam_filenames]\n",
    "spam_data = ham_words + spam_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = list(map(lambda x: x[0], spam_data))\n",
    "y = list(map(lambda x: x[1], spam_data))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We establish the proportion of documents that contain a specific word are classified as spam/not spam. This will be used in the framework of Naive Bayes; picking out documents containing words that feature more in spam documents than ham documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_words(documents):\n",
    "    counts = defaultdict(lambda: [0,0])\n",
    "    for i, document in enumerate(documents):\n",
    "        for word in document:\n",
    "            counts[word][1 if y_train[i] else 0] += 1 # Add 1 to spam counter if the y label is spam otherwise ham counter\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure how frequent each word appears in a spam/ham document and report it out. An added k term is done to make probabilities non-zero, avoiding cases where words that don't appear in ham end up always being classified as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smoothing k term for words that appear on only one side of spam/ham\n",
    "# so that a new email that has a word that features only in the ham training set does not always get classified as ham \n",
    "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
    "    return [(w,\n",
    "            (spam + k) / (total_spams + 2 * k),\n",
    "            (non_spam + k) / (total_non_spams + 2 * k))\n",
    "            for w, (non_spam, spam) in counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def spam_probability(word_probs, message):\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
    "    \n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "        # if word appears in message add the log probability of seeing it\n",
    "        if word in message:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "        # if the word doesn't appear in message add the log probability of not seeing it\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "            \n",
    "    prob_if_spam = math.exp(log_prob_if_spam) + 1e-100\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam) + 1e-100\n",
    "    \n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_frequencies = count_words(X_train)\n",
    "# num_spams = len([i for i, message in enumerate(X_train) if y_train[i]])\n",
    "# num_non_spams = len(X_train) - num_spams\n",
    "# word_prob = word_probabilities(word_frequencies, num_spams, num_non_spams, k=0.5)\n",
    "# word_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the NLTK library we can strip out words from the Counters that are strictly nouns or not words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import nltk\n",
    "\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "\n",
    "class SelectNouns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X = [list(X[i]) for i, _ in enumerate(X)]\n",
    "        tags = [nltk.pos_tag(document) for document in X]\n",
    "        nouns = [[noun[0] for noun in document if is_noun(noun[1])] for document in tags]\n",
    "        return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "noun_transformer = SelectNouns()\n",
    "spam_data_prepared = noun_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of Naive Bayes classifier using word frequencies. A default probability threshold to classify spam is set to 0.5, which can be adjusted. In addition the option exists to output the scores, after which the threshold can be adjusted to improve the precision/reclal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k = 0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "        \n",
    "    def fit(self, training_set):\n",
    "        num_spams = len([message for i, message in enumerate(training_set) if y_train[i]])\n",
    "        num_non_spams = len([message for i, message in enumerate(training_set) if not y_train[i]])\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts,\n",
    "                                            num_spams,\n",
    "                                            num_non_spams,\n",
    "                                            self.k)\n",
    "    def predict(self, messages, threshold = 0.5, scores = False):\n",
    "        if scores:\n",
    "            return [spam_probability(self.word_probs, message) for message in messages]\n",
    "        else:\n",
    "            return [spam_probability(self.word_probs, message) > threshold for message in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the training set and apply the Naive Bayes classifier, outputting the raw scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_clf = NaiveBayesClassifier()\n",
    "nb_clf.fit(spam_data_prepared)\n",
    "\n",
    "spam_test_prepared = noun_transformer.fit_transform(X_test)\n",
    "predictions = nb_clf.predict(spam_test_prepared, scores = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support of the scores are scattered across the two extremes and the middle. Threshold needs to be set sufficiently low to improve the recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUcDOpgobeDEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b412b55e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(predictions,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a range of thresholds from 1 to 10% we can see if there is a level that gives a better F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.883333333333\n",
      "Precision: 0.59842519685\n",
      "Recall: 0.8\n",
      "F1 Score: 0.684684684685\n",
      "Predicted Number of Spam: 127 Actual Spam 95\n",
      "Accuracy: 0.881666666667\n",
      "Precision: 0.595238095238\n",
      "Recall: 0.789473684211\n",
      "F1 Score: 0.678733031674\n",
      "Predicted Number of Spam: 126 Actual Spam 95\n",
      "Accuracy: 0.878333333333\n",
      "Precision: 0.588709677419\n",
      "Recall: 0.768421052632\n",
      "F1 Score: 0.666666666667\n",
      "Predicted Number of Spam: 124 Actual Spam 95\n",
      "Accuracy: 0.875\n",
      "Precision: 0.581967213115\n",
      "Recall: 0.747368421053\n",
      "F1 Score: 0.654377880184\n",
      "Predicted Number of Spam: 122 Actual Spam 95\n",
      "Accuracy: 0.875\n",
      "Precision: 0.581967213115\n",
      "Recall: 0.747368421053\n",
      "F1 Score: 0.654377880184\n",
      "Predicted Number of Spam: 122 Actual Spam 95\n",
      "Accuracy: 0.876666666667\n",
      "Precision: 0.586776859504\n",
      "Recall: 0.747368421053\n",
      "F1 Score: 0.657407407407\n",
      "Predicted Number of Spam: 121 Actual Spam 95\n",
      "Accuracy: 0.876666666667\n",
      "Precision: 0.586776859504\n",
      "Recall: 0.747368421053\n",
      "F1 Score: 0.657407407407\n",
      "Predicted Number of Spam: 121 Actual Spam 95\n",
      "Accuracy: 0.876666666667\n",
      "Precision: 0.586776859504\n",
      "Recall: 0.747368421053\n",
      "F1 Score: 0.657407407407\n",
      "Predicted Number of Spam: 121 Actual Spam 95\n",
      "Accuracy: 0.875\n",
      "Precision: 0.583333333333\n",
      "Recall: 0.736842105263\n",
      "F1 Score: 0.651162790698\n",
      "Predicted Number of Spam: 120 Actual Spam 95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "for i in range(1,10):\n",
    "    pred = [score > i / 100.0 for score in predictions]\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
    "    print(\"Precision:\", precision_score(y_test, pred))\n",
    "    print(\"Recall:\", recall_score(y_test, pred))\n",
    "    print(\"F1 Score:\", f1_score(y_test, pred))\n",
    "    print(\"Predicted Number of Spam:\", sum(pred), \"Actual Spam\", sum(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
